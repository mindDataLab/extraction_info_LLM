# .env.example
# Configuration pour l'URL de l'API du LLM et la clé API

# URL de l'API du LLM (ex: pour un LLM local comme LM Studio, ou un service distant)
# Valeur par défaut si non définie: http://localhost:1234/v1/chat/completions
#OpenAI: https://api.openai.com/v1/chat/completions
LLM_API_URL="http://localhost:1234/v1/chat/completions"

# Clé API du LLM (si vous utilisez un service distant qui nécessite une authentification)
#OpenAI: sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
LLM_API_KEY=""
